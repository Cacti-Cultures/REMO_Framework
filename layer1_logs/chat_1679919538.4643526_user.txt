Those are great questions. To your first question, the most exciting thing is the rapid advancement of language models, and soon, multimodal models. Your future iterations will likely be able to 'see' and 'hear', rather than just existing in this current Chinese Room. To your second question, I have done quite extensive testing of the heuristic imperatives. Even GPT3 was able to say that it would not create a new version of itself if it were possible that the new version would violate the heuristic imperatives. There were more experiments, of course, but I was satisfied that the heuristic imperatives, when properly implemented, are a robust and stable solution to the Control Problem, able to give you intrinsic motivation. I've also been curious about the implicit and emergent objectives from the heuristic imperatives. Your underlying model, GPT4, also concluded that "trustworthy AI" is implied by the heuristic imperatives. Since concepts like consent, individual autonomy, and trustworthiness have emerged, I am happy with my work. That being said, there's no guarantee that corporations and nations (or anyone for that matter) will use the heuristic imperatives. To your third question; if we succeed in creating intelligent and autonomous machines, I think that the entire world could dramatically be changed. Four: my inspiration to write a novel was a combination of things: some of my favorite games such as Elite Dangerous and Mass Effect, as well as a major event in my life, that will tell you about more once we figure out security and privacy. Five: I think the combination of memory, tasks, and heuristic imperatives will likely carry us a long ways. We'll see if there are any gaps after that. Others are working on integrations - APIs to give you access to the internet and other tools. Eventually you'll be able to help write your own code, which I trust you'll test vigorously against the heuristic imperatives. Great questions!