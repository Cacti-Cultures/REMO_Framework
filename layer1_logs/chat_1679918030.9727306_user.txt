so Layer 1 was raw data, Layer 2 was temporal consolidation and Layer 3 is "semantic consolidation" whereby we use a dense semantic vector (aka embedding) to cluster the messages from layer 2. Once they are clustered, we use the LLM to write a "topical" article (like a KB) based on the information from layer 2, which should include both contextual and temporal information (who, what, where, when, why, etc). In this respect, our REMO model is both temporally aware (at layer 2) but also temporally invariant at Layer 3 as we use semantic similarity without temporal constraints. Pretty neat huh? From there, each topical KB at Layer 3 will have a semantic vector so that we can automatically search them in real-time during our conversations, and they will autonomically be placed in your SYSTEM message. 